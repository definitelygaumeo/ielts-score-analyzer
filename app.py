"""
IELTS Score Analyzer - AI Document Summarizer
Backend API using Flask + Optional LLM Integration
"""

from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
import os
import json
from datetime import datetime
from io import BytesIO

app = Flask(__name__)
CORS(app)

# Optional: LLM Integration (uncomment and configure as needed)
# from openai import OpenAI
# from anthropic import Anthropic

# Configuration
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', '')

# IELTS Band Descriptions
BAND_DESCRIPTIONS = {
    9: "Expert User - Th√†nh th·∫°o ho√†n to√†n",
    8: "Very Good User - R·∫•t th√†nh th·∫°o", 
    7: "Good User - Th√†nh th·∫°o",
    6: "Competent User - ƒê·ªß nƒÉng l·ª±c",
    5: "Modest User - Khi√™m t·ªën",
    4: "Limited User - H·∫°n ch·∫ø",
    3: "Extremely Limited - R·∫•t h·∫°n ch·∫ø",
    2: "Intermittent User - Kh√¥ng ·ªïn ƒë·ªãnh",
    1: "Non User - Kh√¥ng s·ª≠ d·ª•ng ƒë∆∞·ª£c"
}

# Skill names in Vietnamese
SKILL_NAMES = {
    'listening': 'Nghe (Listening)',
    'speaking': 'N√≥i (Speaking)',
    'reading': 'ƒê·ªçc (Reading)',
    'writing': 'Vi·∫øt (Writing)'
}

# Comprehensive recommendations database
RECOMMENDATIONS = {
    'listening': {
        'low': [
            "Nghe podcast ti·∫øng Anh h√†ng ng√†y (BBC Learning English, IELTS Liz, 6 Minute English)",
            "Xem phim/series c√≥ ph·ª• ƒë·ªÅ ti·∫øng Anh, sau ƒë√≥ d·∫ßn b·ªè ph·ª• ƒë·ªÅ",
            "Luy·ªán nghe v·ªõi c√°c b√†i test IELTS Listening th·ª±c t·∫ø t·ª´ Cambridge",
            "T·∫≠p nghe c√°c gi·ªçng kh√°c nhau: British, American, Australian",
            "S·ª≠ d·ª•ng app nh∆∞ ELSA Speak ho·∫∑c Speechling ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng nghe"
        ],
        'medium': [
            "TƒÉng ƒë·ªô kh√≥ b·∫±ng c√°ch nghe TED Talks, documentaries",
            "Practice note-taking skills khi nghe c√°c b√†i gi·∫£ng academic",
            "L√†m quen v·ªõi t·∫•t c·∫£ c√°c d·∫°ng c√¢u h·ªèi IELTS Listening",
            "Nghe v√† shadowing theo ƒë·ªÉ c·∫£i thi·ªán c·∫£ speaking l·∫´n listening"
        ],
        'high': [
            "Duy tr√¨ b·∫±ng c√°ch nghe tin t·ª©c qu·ªëc t·∫ø h√†ng ng√†y (BBC, CNN)",
            "Th·ª≠ th√°ch b·∫£n th√¢n v·ªõi academic lectures t·ª´ Coursera, edX",
            "Luy·ªán nghe c√°c ch·ªß ƒë·ªÅ chuy√™n ng√†nh ph·ª©c t·∫°p"
        ]
    },
    'speaking': {
        'low': [
            "Th·ª±c h√†nh n√≥i m·ªói ng√†y, t·ª± ghi √¢m v√† nghe l·∫°i ƒë·ªÉ t·ª± ƒë√°nh gi√°",
            "T√¨m partner luy·ªán Speaking ho·∫∑c s·ª≠ d·ª•ng app nh∆∞ Cambly, iTalki",
            "H·ªçc v√† luy·ªán c√°c topic th∆∞·ªùng g·∫∑p trong IELTS Speaking Part 1, 2, 3",
            "X√¢y d·ª±ng vocabulary theo ch·ªß ƒë·ªÅ v·ªõi collocations v√† phrases",
            "T·∫≠p ph√°t √¢m ƒë√∫ng c√°c √¢m kh√≥ v√† luy·ªán word stress"
        ],
        'medium': [
            "T·∫≠p tr·∫£ l·ªùi c√¢u h·ªèi Part 2 v·ªõi cue card trong 2 ph√∫t",
            "H·ªçc c√°ch ph√°t tri·ªÉn √Ω t∆∞·ªüng v√† ƒë∆∞a v√≠ d·ª• c·ª• th·ªÉ",
            "C·∫£i thi·ªán pronunciation, intonation v√† connected speech",
            "H·ªçc c√°ch s·ª≠ d·ª•ng fillers t·ª± nhi√™n v√† tr√°nh ng·∫≠p ng·ª´ng"
        ],
        'high': [
            "Th·ª±c h√†nh tranh lu·∫≠n v√† th·∫£o lu·∫≠n c√°c ch·ªß ƒë·ªÅ ph·ª©c t·∫°p",
            "H·ªçc idioms, phrasal verbs v√† advanced vocabulary",
            "T·∫≠p paraphrase c√¢u h·ªèi v√† s·ª≠ d·ª•ng ng√¥n ng·ªØ ƒëa d·∫°ng"
        ]
    },
    'reading': {
        'low': [
            "ƒê·ªçc s√°ch b√°o ti·∫øng Anh h√†ng ng√†y (The Guardian, BBC News, The Economist)",
            "B·∫Øt ƒë·∫ßu v·ªõi c√°c b√†i ƒë·ªçc ng·∫Øn ph√π h·ª£p level, t·ª´ t·ª´ tƒÉng ƒë·ªô d√†i",
            "H·ªçc k·ªπ nƒÉng skimming (ƒë·ªçc l∆∞·ªõt) v√† scanning (t√¨m th√¥ng tin c·ª• th·ªÉ)",
            "X√¢y d·ª±ng vocabulary th√¥ng qua ƒë·ªçc v√† ghi ch√©p t·ª´ m·ªõi v√†o flashcard",
            "S·ª≠ d·ª•ng app nh∆∞ Kindle v·ªõi dictionary t√≠ch h·ª£p"
        ],
        'medium': [
            "L√†m quen v·ªõi t·∫•t c·∫£ c√°c d·∫°ng b√†i Reading IELTS (True/False/NG, Matching, etc.)",
            "T·∫≠p ƒë·ªçc nhanh v√† t√¨m th√¥ng tin hi·ªáu qu·∫£ trong th·ªùi gian gi·ªõi h·∫°n",
            "ƒê·ªçc academic articles v√† research papers ƒë·ªÉ quen v·ªõi vƒÉn phong h·ªçc thu·∫≠t",
            "H·ªçc c√°ch identify main ideas v√† supporting details"
        ],
        'high': [
            "ƒê·ªçc c√°c t√†i li·ªáu chuy√™n ng√†nh ph·ª©c t·∫°p (journals, reports)",
            "C·∫£i thi·ªán t·ªëc ƒë·ªô ƒë·ªçc m√† v·∫´n duy tr√¨ comprehension cao",
            "ƒê·ªçc v√† ph√¢n t√≠ch c√°c b√†i vƒÉn argumentative"
        ]
    },
    'writing': {
        'low': [
            "Vi·∫øt nh·∫≠t k√Ω b·∫±ng ti·∫øng Anh m·ªói ng√†y ƒë·ªÉ t·∫°o th√≥i quen",
            "H·ªçc c·∫•u tr√∫c b√†i lu·∫≠n IELTS Task 1 (report) v√† Task 2 (essay)",
            "Luy·ªán vi·∫øt c√¢u ph·ª©c (complex sentences) v·ªõi linking words",
            "Nh·ªù gi√°o vi√™n ho·∫∑c native speaker ch·ªØa b√†i vi·∫øt v√† h·ªçc t·ª´ feedback",
            "H·ªçc c√°c m·∫´u c√¢u academic writing ph·ªï bi·∫øn"
        ],
        'medium': [
            "T·∫≠p ph√¢n t√≠ch ƒë·ªÅ v√† l·∫≠p d√†n √Ω (outline) tr∆∞·ªõc khi vi·∫øt",
            "H·ªçc c√°ch paraphrase hi·ªáu qu·∫£ v√† s·ª≠ d·ª•ng synonyms ƒëa d·∫°ng",
            "Vi·∫øt √≠t nh·∫•t 2-3 b√†i essay m·ªói tu·∫ßn v√† t·ª± ch·∫•m theo rubric",
            "H·ªçc c√°ch vi·∫øt introduction v√† conclusion ·∫•n t∆∞·ª£ng"
        ],
        'high': [
            "T·∫≠p vi·∫øt c√°c b√†i lu·∫≠n ph·ª©c t·∫°p v·ªõi nhi·ªÅu g√≥c nh√¨n kh√°c nhau",
            "C·∫£i thi·ªán academic vocabulary v√† formal expressions",
            "H·ªçc c√°ch s·ª≠ d·ª•ng v√≠ d·ª• v√† data ƒë·ªÉ support arguments"
        ]
    }
}


def calculate_overall(scores: dict) -> float:
    """Calculate overall IELTS band score"""
    total = sum(scores.values())
    avg = total / 4
    # Round to nearest 0.5
    return round(avg * 2) / 2


def get_score_level(score: float) -> str:
    """Categorize score level"""
    if score >= 7:
        return 'high'
    elif score >= 5:
        return 'medium'
    return 'low'


def get_band_description(score: float) -> str:
    """Get band description for a score"""
    band = int(score)
    band = max(1, min(9, band))
    return BAND_DESCRIPTIONS.get(band, "")


def analyze_scores_rule_based(scores: dict, student_name: str) -> dict:
    """
    Rule-based analysis of IELTS scores
    Returns structured analysis with summary, strengths, weaknesses, recommendations
    """
    overall = calculate_overall(scores)
    
    # Create skill array with scores
    skills = [
        {'name': 'listening', 'score': scores['listening'], 'label': SKILL_NAMES['listening']},
        {'name': 'speaking', 'score': scores['speaking'], 'label': SKILL_NAMES['speaking']},
        {'name': 'reading', 'score': scores['reading'], 'label': SKILL_NAMES['reading']},
        {'name': 'writing', 'score': scores['writing'], 'label': SKILL_NAMES['writing']}
    ]
    
    # Sort by score
    sorted_skills = sorted(skills, key=lambda x: x['score'], reverse=True)
    strengths = [s for s in sorted_skills if s['score'] >= overall]
    weaknesses = [s for s in sorted_skills if s['score'] < overall]
    
    # Generate summary
    summary_parts = [f"H·ªçc vi√™n {student_name} ƒë·∫°t ƒëi·ªÉm IELTS t·ªïng th·ªÉ {overall}."]
    
    if strengths:
        strength_names = [s['label'].split(' ')[0] for s in strengths]
        summary_parts.append(f"C√≥ kh·∫£ nƒÉng {' v√† '.join(strength_names)} t·ªët")
        if strengths[0]['score'] >= 7:
            summary_parts[-1] += f" v·ªõi ƒëi·ªÉm n·ªïi b·∫≠t ·ªü k·ªπ nƒÉng {strengths[0]['label'].split(' ')[0]} ({strengths[0]['score']})."
        else:
            summary_parts[-1] += "."
    
    if weaknesses:
        weakness_names = [w['label'].split(' ')[0] for w in weaknesses]
        summary_parts.append(
            f"Tuy nhi√™n, {' v√† '.join(weakness_names)} c√≤n h·∫°n ch·∫ø "
            "do c√≥ th·ªÉ ch∆∞a th∆∞·ªùng xuy√™n luy·ªán t·∫≠p c√°c k·ªπ nƒÉng n√†y."
        )
    
    summary = " ".join(summary_parts)
    
    # Generate recommendations for weak skills
    recommendations_list = []
    for skill in weaknesses:
        level = get_score_level(skill['score'])
        skill_recs = RECOMMENDATIONS[skill['name']][level]
        recommendations_list.append({
            'skill': skill['label'],
            'score': skill['score'],
            'items': skill_recs
        })
    
    # Also add some recommendations for maintaining strengths
    for skill in strengths[:1]:  # Top strength
        level = get_score_level(skill['score'])
        skill_recs = RECOMMENDATIONS[skill['name']][level]
        recommendations_list.append({
            'skill': skill['label'] + ' (Duy tr√¨)',
            'score': skill['score'],
            'items': skill_recs[:2]  # Just top 2 recommendations
        })
    
    # Generate action items
    action_items = []
    if weaknesses:
        weakest = weaknesses[-1]
        action_items.append(
            f"∆Øu ti√™n c·∫£i thi·ªán k·ªπ nƒÉng {weakest['label'].split(' ')[0]} "
            f"(hi·ªán t·∫°i: {weakest['score']}, m·ª•c ti√™u: {min(9, weakest['score'] + 1)})"
        )
    
    action_items.extend([
        f"ƒê·∫∑t m·ª•c ti√™u ƒë·∫°t {min(9, overall + 0.5)} trong 3 th√°ng t·ªõi",
        "Luy·ªán t·∫≠p √≠t nh·∫•t 2 ti·∫øng m·ªói ng√†y, t·∫≠p trung v√†o c√°c k·ªπ nƒÉng y·∫øu",
        "L√†m mock test ƒë·∫ßy ƒë·ªß 2 tu·∫ßn/l·∫ßn ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô",
        "Tham gia study group ho·∫∑c t√¨m tutor ƒë·ªÉ ƒë∆∞·ª£c h∆∞·ªõng d·∫´n"
    ])
    
    return {
        'student_name': student_name,
        'overall': overall,
        'band_description': get_band_description(overall),
        'skills': skills,
        'strengths': [
            {'skill': s['label'], 'score': s['score'], 
             'status': 'Xu·∫•t s·∫Øc' if s['score'] >= 7 else 'T·ªët'}
            for s in strengths
        ],
        'weaknesses': [
            {'skill': w['label'], 'score': w['score'], 'status': 'C·∫ßn c·∫£i thi·ªán'}
            for w in weaknesses
        ],
        'summary': summary,
        'recommendations': recommendations_list,
        'action_items': action_items,
        'analyzed_at': datetime.now().isoformat()
    }


def analyze_with_llm(scores: dict, student_name: str, provider: str = 'openai') -> dict:
    """
    Use LLM (GPT-4 / Claude) for more sophisticated analysis
    Falls back to rule-based if API not configured
    """
    # Prepare the prompt
    prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n IELTS. H√£y ph√¢n t√≠ch ƒëi·ªÉm IELTS c·ªßa h·ªçc vi√™n v√† ƒë∆∞a ra nh·∫≠n x√©t, ƒë·ªÅ xu·∫•t c·∫£i thi·ªán.

Th√¥ng tin h·ªçc vi√™n:
- T√™n: {student_name}
- Listening: {scores['listening']}
- Speaking: {scores['speaking']}  
- Reading: {scores['reading']}
- Writing: {scores['writing']}

H√£y ph√¢n t√≠ch v√† ƒë∆∞a ra:
1. T√≥m t·∫Øt ƒë√°nh gi√° t·ªïng th·ªÉ (2-3 c√¢u)
2. ƒêi·ªÉm m·∫°nh c·ªßa h·ªçc vi√™n
3. ƒêi·ªÉm y·∫øu c·∫ßn c·∫£i thi·ªán
4. ƒê·ªÅ xu·∫•t c·ª• th·ªÉ cho t·ª´ng k·ªπ nƒÉng y·∫øu (resources, ph∆∞∆°ng ph√°p h·ªçc)
5. Action items - k·∫ø ho·∫°ch h√†nh ƒë·ªông c·ª• th·ªÉ trong 1-3 th√°ng

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn v√† th·ª±c t·∫ø."""

    # Try OpenAI
    if provider == 'openai' and OPENAI_API_KEY:
        try:
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY)
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "B·∫°n l√† chuy√™n gia t∆∞ v·∫•n IELTS v·ªõi nhi·ªÅu nƒÉm kinh nghi·ªám."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            llm_analysis = response.choices[0].message.content
            
            # Combine with rule-based analysis
            base_analysis = analyze_scores_rule_based(scores, student_name)
            base_analysis['llm_analysis'] = llm_analysis
            base_analysis['llm_provider'] = 'OpenAI GPT-4'
            return base_analysis
            
        except Exception as e:
            print(f"OpenAI API error: {e}")
    
    # Try Anthropic Claude
    if provider == 'anthropic' and ANTHROPIC_API_KEY:
        try:
            from anthropic import Anthropic
            client = Anthropic(api_key=ANTHROPIC_API_KEY)
            response = client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1024,
                messages=[{"role": "user", "content": prompt}]
            )
            llm_analysis = response.content[0].text
            
            base_analysis = analyze_scores_rule_based(scores, student_name)
            base_analysis['llm_analysis'] = llm_analysis
            base_analysis['llm_provider'] = 'Anthropic Claude'
            return base_analysis
            
        except Exception as e:
            print(f"Anthropic API error: {e}")
    
    # Fallback to rule-based
    return analyze_scores_rule_based(scores, student_name)


@app.route('/')
def index():
    """Serve the main page"""
    return render_template('index.html')


@app.route('/api/analyze', methods=['POST'])
def analyze():
    """API endpoint to analyze IELTS scores"""
    try:
        data = request.json
        
        # Validate input
        required_fields = ['student_name', 'listening', 'speaking', 'reading', 'writing']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing field: {field}'}), 400
        
        scores = {
            'listening': float(data['listening']),
            'speaking': float(data['speaking']),
            'reading': float(data['reading']),
            'writing': float(data['writing'])
        }
        
        # Validate score ranges
        for skill, score in scores.items():
            if not 0 <= score <= 9:
                return jsonify({'error': f'Invalid {skill} score. Must be 0-9'}), 400
        
        student_name = data['student_name']
        use_llm = data.get('use_llm', False)
        llm_provider = data.get('llm_provider', 'openai')
        
        # Perform analysis
        if use_llm:
            analysis = analyze_with_llm(scores, student_name, llm_provider)
        else:
            analysis = analyze_scores_rule_based(scores, student_name)
        
        return jsonify(analysis)
        
    except ValueError as e:
        return jsonify({'error': f'Invalid score value: {str(e)}'}), 400
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/export', methods=['POST'])
def export_report():
    """Export analysis as text/PDF report"""
    try:
        data = request.json
        analysis = data.get('analysis', {})
        
        # Generate report content
        report = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë           IELTS SCORE ANALYSIS REPORT                        ‚ïë
‚ïë           B√ÅO C√ÅO PH√ÇN T√çCH ƒêI·ªÇM IELTS                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìÖ Ng√†y ph√¢n t√≠ch: {datetime.now().strftime('%d/%m/%Y %H:%M')}
üë§ H·ªçc vi√™n: {analysis.get('student_name', 'N/A')}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìä ƒêI·ªÇM T·ªîNG TH·ªÇ: {analysis.get('overall', 0)}
   {analysis.get('band_description', '')}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìà CHI TI·∫æT ƒêI·ªÇM:
"""
        for skill in analysis.get('skills', []):
            bar_length = int(skill['score'] / 9 * 20)
            bar = '‚ñà' * bar_length + '‚ñë' * (20 - bar_length)
            report += f"   ‚Ä¢ {skill['label']}: {skill['score']} [{bar}]\n"

        report += f"""
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìù T√ìM T·∫ÆT ƒê√ÅNH GI√Å:
{analysis.get('summary', '')}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üí™ ƒêI·ªÇM M·∫†NH:
"""
        for s in analysis.get('strengths', []):
            report += f"   ‚úì {s['skill']}: {s['score']} - {s['status']}\n"

        report += """
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìâ ƒêI·ªÇM C·∫¶N C·∫¢I THI·ªÜN:
"""
        for w in analysis.get('weaknesses', []):
            report += f"   ‚ö† {w['skill']}: {w['score']} - {w['status']}\n"

        report += """
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ ƒê·ªÄ XU·∫§T C·∫¢I THI·ªÜN:
"""
        for rec in analysis.get('recommendations', []):
            report += f"\n   üìå {rec['skill']}:\n"
            for item in rec['items']:
                report += f"      ‚Üí {item}\n"

        report += """
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìå K·∫æ HO·∫†CH H√ÄNH ƒê·ªòNG:
"""
        for i, action in enumerate(analysis.get('action_items', []), 1):
            report += f"   {i}. {action}\n"

        if 'llm_analysis' in analysis:
            report += f"""
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

ü§ñ PH√ÇN T√çCH AI ({analysis.get('llm_provider', 'AI')}):
{analysis['llm_analysis']}
"""

        report += """
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
B√°o c√°o ƒë∆∞·ª£c t·∫°o b·ªüi IELTS Score Analyzer - AI Document Summarizer
"""

        # Return as downloadable file
        buffer = BytesIO()
        buffer.write(report.encode('utf-8'))
        buffer.seek(0)
        
        filename = f"IELTS_Report_{analysis.get('student_name', 'Student')}_{datetime.now().strftime('%Y%m%d')}.txt"
        
        return send_file(
            buffer,
            mimetype='text/plain',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/batch-analyze', methods=['POST'])
def batch_analyze():
    """Analyze multiple students from CSV data"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # Read CSV
        import csv
        from io import StringIO
        
        content = file.read().decode('utf-8')
        reader = csv.DictReader(StringIO(content))
        
        results = []
        for row in reader:
            try:
                scores = {
                    'listening': float(row.get('listening', 0)),
                    'speaking': float(row.get('speaking', 0)),
                    'reading': float(row.get('reading', 0)),
                    'writing': float(row.get('writing', 0))
                }
                student_name = row.get('student_name', row.get('name', 'Unknown'))
                
                analysis = analyze_scores_rule_based(scores, student_name)
                results.append(analysis)
            except Exception as e:
                results.append({'error': str(e), 'row': row})
        
        return jsonify({'results': results, 'count': len(results)})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # Create templates directory if it doesn't exist
    os.makedirs('templates', exist_ok=True)
    
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë     IELTS Score Analyzer - AI Document Summarizer            ‚ïë
‚ïë     Server running at http://localhost:5000                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

To use with LLM:
  - Set OPENAI_API_KEY environment variable for GPT-4
  - Set ANTHROPIC_API_KEY environment variable for Claude

API Endpoints:
  POST /api/analyze      - Analyze single student
  POST /api/export       - Export report
  POST /api/batch-analyze - Analyze multiple students (CSV)
""")
    
    app.run(debug=True, port=5000)

